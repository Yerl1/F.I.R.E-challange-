Metadata-Version: 2.4
Name: pipeline-service
Version: 0.1.0
Summary: DDD-oriented ticket pipeline service built with LangGraph
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: numpy<2
Requires-Dist: langgraph>=0.2.50
Requires-Dist: requests>=2.32.0
Requires-Dist: fasttext>=0.9.3
Requires-Dist: Pillow>=10.0.0
Requires-Dist: paddleocr==2.7.3
Requires-Dist: paddlepaddle==2.6.2
Provides-Extra: dev
Requires-Dist: pytest>=8.0.0; extra == "dev"

# Pipeline Service

DDD-style pipeline service scaffold using LangGraph and Ollama integration points.

## What is implemented now

- Full project structure for a standalone `pipeline-service` repository.
- LangGraph workflow with required branching/join topology.
- Stub node logic with deterministic mock outputs.
- CLI runner for sample ticket processing.
- In-memory + JSON-file persistence stub.
- Smoke test for end-to-end graph execution.

## Run with Docker Compose

```bash
cd pipeline-service
docker-compose up --build
```

The default compose command runs a smoke graph execution.

## Ollama model setup

The service is non-blocking in mock mode (`MOCK_LLM=1`), so it runs even if model is not pulled.

To prepare real model usage:

```bash
docker-compose up -d ollama
docker exec -it fire-ollama ollama pull llama3.2:1b
```

Then disable mock mode:

```bash
MOCK_LLM=0 docker-compose up --build
```

## Local run (without Docker)

```bash
cd pipeline-service
python -m venv .venv
source .venv/bin/activate
pip install -e '.[dev]'
python -m pipeline_service.main --sample
pytest -q
```

## fastText language model setup

Language detection uses fastText model `lid.176.ftz`.

```bash
cd pipeline-service
source .venv/bin/activate
make install_deps
make setup_fasttext
```

Set model path (already included in root `.env`):

```bash
FASTTEXT_MODEL_PATH=/home/arsen/F.I.R.E-challange-/pipeline-service/models/lid.176.ftz
```

If you use shell exports instead of `.env`:

```bash
export FASTTEXT_MODEL_PATH=/home/arsen/F.I.R.E-challange-/pipeline-service/models/lid.176.ftz
```

## Where to change logic

- Graph topology: `src/pipeline_service/application/graph/ticket_graph.py`
- Nodes: `src/pipeline_service/application/nodes/`
- Domain entities/value objects: `src/pipeline_service/domain/entities/`
- LLM integration: `src/pipeline_service/infrastructure/llm/ollama_client.py`
- Persistence strategy: `src/pipeline_service/infrastructure/persistence/repository.py`
